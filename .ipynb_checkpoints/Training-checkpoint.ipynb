{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7a66cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten ,Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.preprocessing.image import img_to_array,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73d1e553",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = f'cat-vs-dogs-prediction-{int(time.time())}'\n",
    "\n",
    "tensorboard= TensorBoard(log_dir=f'logs\\\\{NAME}\\\\')\n",
    "x=pickle.load(open('x.pkl','rb'))\n",
    "y=pickle.load(open('y.pkl','rb'))\n",
    "# loadingg the save pickle and reading it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db54fa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x/255\n",
    "# lesser value faster proceeing, feature scaling\n",
    "\n",
    "# pixel 0-255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e752b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23000, 100, 100, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape \n",
    "# heinght 100 width 100 3channels Red Blue and Green "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd4c2802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Conv2D: This performs a 2D convolution operation, which is essential for processing image data in Convolutional Neural Networks (CNNs).\n",
    "# MaxPooling2D: This reduces the dimensionality of the data by applying a pooling function (like max pooling) over local regions.\n",
    "# Flatten: This transforms the data from a 2D or 3D format into a 1D vector before feeding it to fully-connected layers.\n",
    "# Dense: This represents a fully-connected layer, commonly used in the final stages of a neural network for classification or regression tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "47be34de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential()\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, input_shape=x.shape[1:], activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d24f36e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "# model.compile: This method is called on a Keras model instance to set up the training process.\n",
    "# optimizer='adam': This argument specifies the optimizer used to update the model's weights during training. Here, 'adam' refers to the Adam optimizer, a popular choice for its efficiency and effectiveness.\n",
    "# loss='sparse_categorical_crossentropy': This argument defines the loss function used to measure how well the model's predictions deviate from the true labels. 'sparse_categorical_crossentropy' is suitable for problems where labels are represented as integers (not one-hot encoded).\n",
    "# metrics=['accuracy']: This argument is a list specifying the metrics to be monitored during training. Here, 'accuracy' is used to track the percentage of correct predictions made by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be440052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m647/647\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 356ms/step - accuracy: 0.5500 - loss: 1.5828 - val_accuracy: 0.5217 - val_loss: 0.6954\n",
      "Epoch 2/5\n",
      "\u001b[1m647/647\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 340ms/step - accuracy: 0.5666 - loss: 0.6789 - val_accuracy: 0.5943 - val_loss: 0.6635\n",
      "Epoch 3/5\n",
      "\u001b[1m647/647\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 350ms/step - accuracy: 0.6014 - loss: 0.6581 - val_accuracy: 0.6439 - val_loss: 0.6412\n",
      "Epoch 4/5\n",
      "\u001b[1m647/647\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 431ms/step - accuracy: 0.6641 - loss: 0.6108 - val_accuracy: 0.7148 - val_loss: 0.5736\n",
      "Epoch 5/5\n",
      "\u001b[1m647/647\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 499ms/step - accuracy: 0.7344 - loss: 0.5344 - val_accuracy: 0.6957 - val_loss: 0.5728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x24211ff2a90>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,epochs=5, validation_split=0.1,batch_size=32, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7dc11dd1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Example usage: predict class probabilities for a new image\u001b[39;00m\n\u001b[0;32m     22\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAcer\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcatsanddogsclassification\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdogscats\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcat\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcat.0.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Replace with your image path\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m class_name, probability \u001b[38;5;241m=\u001b[39m predict_class(image_path)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted class: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Probability: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprobability\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[19], line 10\u001b[0m, in \u001b[0;36mpredict_class\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_class\u001b[39m(image_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAcer\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcatsanddogsclassification\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdogscats\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcat\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcat.0.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      6\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m  Preprocesses an image, makes a prediction using the trained model,\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;03m  and returns the predicted class (cat or dog) with its probability.\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m   img \u001b[38;5;241m=\u001b[39m load_img(image_path, target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m100\u001b[39m))  \u001b[38;5;66;03m# Resize the image\u001b[39;00m\n\u001b[0;32m     11\u001b[0m   img \u001b[38;5;241m=\u001b[39m img_to_array(img)  \u001b[38;5;66;03m# Convert to array\u001b[39;00m\n\u001b[0;32m     12\u001b[0m   img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mexpand_dims(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# Add a new dimension for batch processing\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_img' is not defined"
     ]
    }
   ],
   "source": [
    "# tensorboard used for comparing the models isualization we can give greater visualization\n",
    "# creating differnt foler through log_dir and running that folder in comman prompt \n",
    "# C:\\Users\\Acer\\Desktop\\catsanddogsclassification>tensorboard --logdir=logs/\n",
    "# no of convo layers max pool layers everthings determines the good data test\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "def predict_class(image_path=r'C:\\Users\\Acer\\Desktop\\catsanddogsclassification\\dogscats\\train\\cat\\cat.0.jpg'):\n",
    "  \"\"\"\n",
    "  Preprocesses an image, makes a prediction using the trained model,\n",
    "  and returns the predicted class (cat or dog) with its probability.\n",
    "  \"\"\"\n",
    "  img = load_img(image_path, target_size=(100, 100))  # Resize the image\n",
    "  img = img_to_array(img)  # Convert to array\n",
    "  img = img.expand_dims(axis=0)  # Add a new dimension for batch processing\n",
    "  img = img / 255.0  # Normalize pixel values\n",
    "\n",
    "  predictions = model.predict(img)[0]  # Make prediction and get probabilities\n",
    "  class_index = predictions.argmax()  # Get the index of the highest probability class\n",
    "  class_name = ('cat', 'dog')[class_index]  # Convert index to class name\n",
    "\n",
    "  return class_name, predictions[class_index]  # Return class name and probability\n",
    "\n",
    "# Example usage: predict class probabilities for a new image\n",
    "image_path = r'C:\\Users\\Acer\\Desktop\\catsanddogsclassification\\dogscats\\train\\cat\\cat.0.jpg'  # Replace with your image path\n",
    "class_name, probability = predict_class(r'C:\\Users\\Acer\\Desktop\\catsanddogsclassification\\dogscats\\train\\cat\\cat.0.jpg')\n",
    "\n",
    "print(f'Predicted class: {class_name}, Probability: {probability:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451e0d21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94205ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
